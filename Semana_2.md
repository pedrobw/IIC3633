## Semana 2

### [Matrix factorization techniques for recommender systems (2009). Koren, Y., Bell, R., & Volinsky, C.](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)

En este documento se discuten incialmente algunas diferencias entre los métodos de filtro colaborativo, como aquellos que discutí la semana pasada, y aquellos basados en el contenido, que pueden evitar los problemas de _cold start_ que presentan los primeros. Igualmente, se habla de algunas diferencias existentes entre el _feedback_ implícito y el _feedback_ explícito para recolectar información pertinente respecto a los gustos y a las preferencias de los usuarios con quienes se trabaja. Todo esto sirve como introducción para el tema que realmente se busca presentar: el uso de modelos matriciales que representen de manera adecuada las preferencias de los usuarios.

De aquí en adelante, al igual que en el documento, consideraremos una cantidad f de factores tomados en cuenta para un modelo, y, para un usuario u y un ítem i, denotaremos por r<sub>ui</sub> el rating dado por el usuario u al ítem i, por q<sub>i</sub> en R<sup>f</sup> el vector que representa la presencia de cada factor en el ítem i, y por p<sub>u</sub> en R<sup>f</sup> el vector que representa la afinidad del usuario u con cada uno de los factores. Los factores en cuestión pueden ser más o menos explícitos y dependerán de cada modelo. Se puede tener interpretaciones muy precisas de ellos, pero también interpretaciones completamente incomprensibles, escondidas bajo la descripción matemática del modelo.

El primer y más simple modelo, que sirve como base para los demás, es un modelo que considera una minimización del error cuadrático considerando una penalización sobre la norma de los vectores (con el fin de minimizar la cantidad de factores que explican el modelo).
> min ∑<sub>u,i </sub>(r<sub>ui</sub> - p<sub>u</sub><sup>T</sup>q<sub>i</sub>)<sup>2</sup> - λ(||p<sub>u</sub>||<sup>2</sup> + ||q<sub>i</sub>||<sup>2</sup>)

Esta simplificación es muy similar a la que se usa en una regresión tipo LASSO que estudié hace unos años en el curso de Métodos de Optimización, sin emabargo me parece algo lamentable que el _paper_ no se dé el tiempo de explicar la razón por la que se utiliza esta forma de minimización, y de esta forma se ve poco intuitiva.

Se proponen dos técnicas para resolver esta forma de problemas, la del descenso del gradiente y la de _alternating least squares (ALS)_ o mínimos cuadrados alternantes, ambas técnicas iterativas que convergen bastante rápido, siendo la primera la más simple y fácil de implementar y usualmente la rápida en matrices dispersas (_sparse_), y la segunda algo más compleja pero paralelizable y preferible cuando las matrices son más densas.

Los modelos siguientes son ya más interesantes y explican los potenciales de agregar variables que agregan información al modelo, como el bias b<sub>u</sub> de un usuario u (visto como la desviación en las calificaciones hechas por el usuario respecto al promedio de la base de datos) y el bias b<sub>i</sub> de un ítem (visto como la desviación en las calificaciones que recibe el ítem que se desea evaluar), o variables que incluyen información temporal o respecto de la confianza de la predicción, como muestran los modelos dados respectivamente por
> min ∑<sub>u,i</sub> (r<sub>ui</sub> - µ - b<sub>u</sub> - b<sub>i</sub> - p<sub>u</sub><sup>T</sup>q<sub>i</sub>)<sup>2</sup> - λ(||p<sub>u</sub>||<sup>2</sup> + ||q<sub>i</sub>||<sup>2</sup> + b<sub>i</sub><sup>2</sup> + b<sub>u</sub><sup>2</sup>)

> min ∑<sub>u,i</sub> (r<sub>ui</sub>(t) - µ - b<sub>u</sub>(t) - b<sub>i</sub>(t) - p<sub>u</sub><sup>T</sup>(t)q<sub>i</sub>(t))<sup>2</sup> - λ(||p<sub>u</sub>(t)||<sup>2</sup> + ||q<sub>i</sub>(t)||<sup>2</sup> + b<sub>i</sub><sup>2</sup>(t) + b<sub>u</sub><sup>2</sup>(t))

> min ∑<sub>u,i</sub> c<sub>ui</sub>(r<sub>ui</sub> - µ - b<sub>u</sub> - b<sub>i</sub> - p<sub>u</sub><sup>T</sup>q<sub>i</sub>)<sup>2</sup> - λ(||p<sub>u</sub>||<sup>2</sup> + ||q<sub>i</sub>||<sup>2</sup> + b<sub>i</sub><sup>2</sup> + b<sub>u</sub><sup>2</sup>)

Se concluye comentando que la utilización de estos métodos (y otros más sofisticados) han terminado por dominar el área de los sistemas recomendadores tras los buenos resultados mostrados en el Netflix Prize. Me parece que es algo razonable, puesto que a diferencia de otras descomposiciones matriciales más directas, estas se basan en un modelo de optimización, que de representar bien la realidad subyacente del comportamiento de los usuarios, efectivamente debiese obtener mejores resultados. Por este mismo motivo, encuentro que podrían haber profundizado mejor en las razones detrás de sus elecciones de modelos y cuáles son las sofisticaciones que han obtenido mejores resultados desde entonces, pero a grandes rasgos parece haber abordado el tema de manera bastante completa e intuitiva.


## [Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf)

Tras una breve discusión sobre los problemas que aparecen al intentar obtener información explícita respecto de las preferencias de los usuarios, se propone con alternativa el uso de información implícita como datos adicionales en los sistemas recomendadores. Por supuesto, estos datos suelen presentar algunas desventajas, como la ausencia de feedback negativo, el ruido inherente que contienen, la falta de información respecto a las preferencias que otorgan (versus la confianza que sí logran representar en cierta medida, al menos para algunos de los marcadores discutidos), o la métrica utilizada para su medición.

Para el caso de estudio particular, correspondiente a un sistema recomendador diseñado para una _box_ de televisión, la variable base de estudio fue llamada r<sub>ui</sub>, y representó el número de veces que un programa i era observado por un usuario u. De ella se derivó una variable binaria p<sub>ui</sub> con valor 1 si r<sub>ui</sub> era positiva y 0 en caso contrario, y otra variable c<sub>ui</sub> para representar la confianza de observar p<sub>ui</sub>, y definida utilizando un parámetro α (determinado empíricamente como α=40) por la expresión:
> c<sub>ui</sub> = 1 + αp<sub>ui</sub>

O alternativamente, los autores mencionaron que, para ɛ apropriado, también fue efectivo utilizar
> c<sub>ui</sub> = 1 + αlog(1 + r<sub>ui</sub>/ɛ)

Se utilizó entonces un modelo similar a los mencionados en el _paper_ precedente, definido por el problema de minimización siguiente:
> min ∑<sub>u,i</sub> c<sub>ui</sub>(p<sub>ui</sub> - x<sub>u</sub><sup>T</sup>y<sub>i</sub>)<sup>2</sup> + λ(∑<sub>u</sub>||x<sub>u</sub>||<sup>2</sup> + ∑<sub>i</sub>||y<sub>i</sub>||<sup>2</sup>)

Lo interesante de este modelo, es que es posible establecer una relación lineal entre las predicciones p<sub>ui</sub> y las acciones pasadas c<sub>uj</sub> (que en el modelo básico antes descrito dependen de r<sub>uj</sub> linealmente) con un arreglo algebraico que permite construir vectores de similaridad ítem-ítem para un usario u dado. Los resultados no decepcionan, pues empíricamente se muestra que, tras una limpieza inteligente para el caso de estudio del documento, en la que se reduce considerablemente la cantidad de datos a tratar, se logra realizar un sistema de recomendación significativamente mejor que las recomendaciones basadas en popularidad y en vecindades, y además es consistente en mostrar que el uso de más factores implícitos hace mejorar las predicciones, lo que valida su uso para los _RecSys_.

Vale además la pena mencionar que los autores agregan en la última sección del _paper_ una discusión en la que se proponen integrar contenido dinámico relacionado al tiempo. Me parece que para su caso de estudio particular, eso es bastante importante, puesto que los programas de televisión y el comportamiento de las personas al mirar televisión depende mucho de los horarios en los que ellos están disponibles y de las horas de emisión de los programas.

Finalmente, quiero decir que es valorable el nivel de detalle técnico en la explicación del modelo empleado, en la factorización matricial y la interpretación que se hizo de las variables empleadas. A diferencia de otros papers que me ha tocado leer en algunos temas de implementación práctica de algoritmos para resolver problemas complejos, este hace un buen énfasis en y desarrollo de lo teórico antes de mostrar su efectividad práctica. Como potencial investigador o desarrollador, creo que este es el aporte que uno debiese hacer desde la investigación en ciencias de la computación, y no limitarse solamente a mostrar resultados.
