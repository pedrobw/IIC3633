## Semana 1

### [How not to sort by Average Rating (2009). Miller, E.](http://www.evanmiller.org/how-not-to-sort-by-average-rating.html)

En el blog de Evan Miller, se discuten algunas alternativas para ordenar recomendaciones en una base de datos con ítems calificados por un grupo de usuarios. Para acercarse a una solución razonable, Miller analiza primero algunas opciones erróneas utilizadas por algunos sitios populares, como la diferencia entre ratings positivos y ratings negativos (utilizada en Urban Dictionnary) y el promedio de ratings (utilizado por Amazon). Se argumenta a través de un ejemplo que la primera privilegia mucho la popularidad por sobre la calificación de los usuarios. En efecto, un ítem que ha recibido más puntuaciones requiere una mucho menor proporción de puntuaciones positivas que aquellos que han sido puntuados menos veces. Luego se razona a través de otro ejemplo que el segundo falla, puesto que un ítem con pocas calificaciones, todas positivas, se va directo al tope de las recomendaciones.

La alternativa que propone para solucionar estos inconvenientes es el de usar el _score de Wilson_, definido como la cota inferior del intervalo de confianza de Wilson para un parámetro Bernoulli. El motivo es que su uso considera tanto la proporción entre positivos y negativos como la cantidad de gente que ha puntuado los ítems en cuestión. Finalmente, Miller propone otros usos para este sistema de recomendación no personalizado, como el filtrado de spam, el listado de _best of_, o el listado de _most emailed_.

Como comentario, me parece que fue una lectura interesante, puesto que abordó alternativas populares para ordenar recomendaciones con simplicidad para proponer una solución más razonable y menos intuitiva que parece mucho más justa. Sin embargo, mi impresión es que no ahondó lo suficiente en los razonamientos, sino que estuvo puramente limitado a los ejemplos para sus justificaciones. Creo que habían más razones a considerar para desechar las opciones propuestas, como por ejemplo, el enorme sesgo que tiene la primera opción propuesta, dado que la opción recomendada suele ser la más popular y es potenciada al estar siempre mostrada primero.

Finalmente, creo que habría sido más interesante evaluar alternativas un poco más complejas que pudiesen aprovechar mejor la estructura con múltiples valores que se utiliza para las cinco estrellas de evaluación en el sistema de Amazon criticado. Dado que no es inmediata la deducción de qué es considerado un rating positivo o uno negativo, una alternativa con intervalos de confianza sobre otro tipo de distribución habría sido más interesante, o al menos una discusión sobre cómo emplearlo en esta situación (como por ejemplo, decir que 1-3 estrellas serán consideradas negativas, y 4-5 serán positivas, o que en lugar de usar valores binarios, utilizaremos la fracción como aproximación del parámetro Bernoulli), especialmente considerando que en el caso de las cinco estrellas, la modelación del _rating_ no coincide con la solución propuesta.

### [Collaborative Filtering Recommender Systems (2007). Schafer, J. B., Frankowski, D., Herlocker, J., & Sen, S.](https://pdfs.semanticscholar.org/d17d/3fa8083c4de1f5545446a1f59da54a1dba21.pdf)

En este documento, se estudia el _collaborative filtering_ o filtrado colaborativo (CF), entendido como el proceso de filtrar o evaluar ítems de cierta base de datos utilizando como punto de base la opinión de otros. En la primera sección, se estudian primero algunos de los posibles usos que tiene el CF para facilitar tareas al usuario (como por ejemplo, encontrar ítems de interés, aconsejar sobre un ítem, encontrar usuarios afines para facilitar las conexiones y el intercambio, encontrar intereses en común dentro de un grupo, balancear las recomendaciones para incluir ítems desconocidos con otros ya utilizados o comprados anteriormente y crear recomendaciones específicas al dominio de interés), luego algunas de las funcionalidades comunes que cumplen los sistemas de filtrado colaborativo (como son la recomendación de ítems, la predicción de la puntuación que se le dará a un ítem dado o la recomendación de ítems bajo restricciones especificadas), y en seguida se describen ciertas propiedades deseables para las bases de datos sobre los que se quieren aplicar estas técnicas (como que haya gran cantidad de ítems, alta proporción de ratings por ítem, gran número de usuarios, y que los usuarios puntúen múltiples ítems), ciertos supuestos razonables sobre las relaciones y significados de los datos (como la comparabilidad entre usuarios, el uso de criterios subjetivos para el filtrado, y la homogeneidad de los ítems que se quieren diferenciar con la técnica) y ciertas propiedades sobre la persistencia temporal de los datos (desde aquella de los ítems en el tiempo a la de los gustos). Finalmente, se hace una pequeña comparación de los escenarios en los que podría ser más deseable utilizar CF en lugar de _content base filtering_ o filtrado basado en el contenido (CBF), y como su uso puede ser complementario para sistemas recomendadores. 

En la segunda sección, se muestran y explican algunos de los algoritmos que se utilizan para hacer este filtrado colaborativo. En primer lugar, se exploran opciones no probabilísticas. Sobre ellas, la primera técnica consiste en predecir el _rating_ que un usuario dará a un ítem basándose en una suerte de promedio ponderado de los ratings dados por usuarios similares (los vecinos) al usuario en cuestión ajustado por el promedio otorgado por los usuarios a los ítems que han consumido. Es interesante destacar que se discuten aquí también cómo generar un set de vecinos adecuado de manera más o menos eficiente, y que se critican algunos problemas que surgen con los enfoques que se usan convencionalmente. La segunda técnica propuesta es muy similar en su razonamiento, pero esta vez se basa en la similaridad entre ítems, en lugar de entre los usuarios. En este caso, se hace ponderan los _ratings_ dados a los ítems calificados por el usuario en cuestión utilizando como pesos las similaridades entre ellos y el ítem que se desea predecir. Cabe destacar acá que, al menos en la [versión del paper que estoy leyendo](https://pdfs.semanticscholar.org/d17d/3fa8083c4de1f5545446a1f59da54a1dba21.pdf), uno de los índices aparece mal (debiese ser r<sub>uj</sub> y no r<sub>ui</sub> en la fórmula (6) de la página 304, puesto que el valor de r<sub>ui</sub> es el que se desconoce). Con respecto a estas técnicas no probabilísticas, los autores establecen igualmente un número de desafíos que deben superar las implementaciones de estas técnicas, como la reducción de las dimensiones del problema, tanto para simplificar los cálculos como para mejorar la noción de vecindad, y las reglas de asociación que se pueden utilizar para reducir la dispersión de los datos.

A continuación, se explotar opciones probabilísticas, esencialmente basados en la idea de redes Bayesianas. En este proceso, la idea es formar una red en la que se puedan determinar el valor esperado del _rating_ que se le asignará a un ítem utilizando para ello una secuencia de probabilidades condicionadas estimadas en base a los datos existentes en la base de datos. Cabe destacar acá que los autores mencionan que, a la fecha, no había suficiente evidencia para afirmar la superioridad de estos métodos a los métodos no probabilísticos antes descritos, sin embargo, me parece que los métodos de estado del arte que han refinado el concepto de redes bayesianas sí han logrado mejores resultados.

Finalmente, en esta sección se establecen algunas formas de reparar y ajustar los datos y los cálculos con el objetivo de evitar problemas prácticos que se dan con frecuencia, como, por ejemplo, ajustar la carencia de puntuaciones (descartando los ítems raramente considerados o ajustando los cálculos para ellos e introduciendo datos artificiales considerando supuestos), adaptar el algoritmo según se requiera hacer una predicción o una recomendación (donde el segundo normalmente requiere un menor costo de memoria), o añadir métricas de confianza para descartar recomendaciones que carecen de sustentos suficientes para respaldarlas.

La sección siguiente es algo más específica al diseño, y se enfoca en estudiar el el tipo de datos que se recogerán para hacer las predicciones. Se menciona primero el trade-off entre la facilidad de recoger los datos del usuario y la significancia de los datos recogidos. En particular, los datos pedidos explícitamente suelen ser más confiables, pero exigen una interacción de parte del usuario que no están necesariamente dispuestos a hacer, mientras que los datos recogidos de manera implícita no requieren una acción adicional del usuario, pero están sujetos a mayor ruido y se necesita una mayor cantidad de ellos para extraer conclusiones. En segundo lugar, se discute la dificultad de obtener puntuaciones explícitas de los usuarios, pero se aclara que las dificultades no son tan grandes dado que estos valoran otras características secundarias de los sistemas recomendadores, como mantener un registro de sus gustos o la gratificación de contribuir, y que además basta con unos pocos usuarios altamente activos para tener un sistema con buenos resultados.

En tercer lugar, se disculten dificultades relacionadas con la escala de puntuación, que suele ser discreta. Me parece destacable notar que aquí mencionan que la frustración de los usuarios por tener escalas insuficientemente precisas fue un problema en MovieLens, pero aún así recientemente Netflix pasó de su sistema de estrellas a un sistema de _likes_, que provee mucha menos información, y que para mí, como usuario, es igualmente frustrante.

Finalmente, en esta sección se menciona el problema de _cold start_, que se da cuando los datos son insuficientes para dar una recomendación pertinente, por ejemplo, para un usuario nuevo que no cuenta con datos, o para un ítem nuevo, que no cuenta calificaciones. Yendo un poco más allá, se aborda el caso de comunidades nuevas. En casos en los que se quiere captar un nuevo grupo de usuarios o clientes, es interesante notar que si no se tiene un modelo pertinente para ellos, será muy difícil demostrarles que se les está ofreciendo realmente una ventaja competitiva al proveerles un servicio.

En la sección siguiente se discute el problema de evaluar un sistema recomendador. A falta de consenso respecto a los criterios a considerar, se proponen diversas métricas que buscan calificar un abanico de atributos de los _RecSys_. Se mencionan, entre ellos que el más común tiene que ver con la precisión de la predicción, que usualmente usa el error absoluto medio (MAE), sin embargo, queda claro que hay una variedad de otros criterios que califican para esto, como la novedad o _novelty_, _i.e._, la capacidad de generar recomendaciones de ítems que eran desconocidos para el usuario, la serendipia o _serendipity_, _i.e._, la capacidad de generar recomendaciones de ítems que el usuario no habría conocido por sus canales existentes de descubrimiento, la cobertura o _coverage_, _i.e._,  la proporción de ítems considerados por el CF (normalmente, restringido a un subset pertinente) sobre el cual es capaz de generar recomendaciones, la tasa de aprendizaje o _learning rate_, _i.e._, la rapidez con la cual el sistema es capaz de generar predicciones adecuadas que cumplan con el objetivo, y la confianza o _confidence_, _i.e._, la capacidad de establecer (bajo cierta probabilidad) la calidad de las recomendaciones. Se nombran además métricas de satisfacción del usuario o métricas comunes de rendimiento de los sitios como posibles criterios de evaluación.

En las secciones que siguen se establecen algunos de los desafíos latentes y problemas recientes a los que se enfrentan quienes desarrollan sistemas de recomendación. Podemos citar entre ellos la dificultad de explicar los resultados de predicción y recomendación que se ofrecen, proveer una interfaz adecuada para los objetivos que se quieren cumplir, especialmente para aprovechar las interacciones sociales y los espacios de visualización, las preocupaciones respecto a la seguridad de la información personal y la privacidad de los usuarios, las dificultades frente a los problemas de confiabilidad, especialmente por aquellos que surgen de proveedores que favorecen sus ítems o de usuarios que atacan a ítems que no son de su agrado.

Finalmente, los autores plantean una última sección con preguntas abiertas (hasta entonces, al menos) respecto a problemáticas de los sistemas recomendadores. Entre ellas, se distinguen las problemáticas algorítmicas, por ejemplo, respecto de buscar mejores métricas de evaluación, generar algoritmos eficientes que recomienden y predigan simultáneamente o que usen el sistema de _tags_ para sus CF, las problemáticas temporales, en las que se busca, por ejemplo, saber la pertinencia temporal (ciclo de vida, tendencias...) o cardinal (cantidad necesaria) de los ítems a evaluar, entender el ciclo de vida de los usuarios y los requerimientos sobre sus datos que permitirán asegurar cuándo el CF actúa de acuerdo a lo que se espera de él en términos de cantidad y origen temporal, y el ciclo de entender el ciclo de vida de los ratings, en particular, en cuanto a su persistencia o expiración, y a otros requerimientos sobre el número o la robustez de ellas para generar un filtro competente. Finalmente, se hace un breve cuestionamiento las interfaces, librerías y bases de datos que podrían permitir un mayor acceso a este tipo de herramientas.

Respecto de este documento, quisiera comentar que me pareció que hizo un análisis cualitativo bastante completo del área y logró captar mi interés durante casi toda la lectura con las reflexiones críticas respecto a las dificultades a tener en cuenta al momento de diseñar un filtro colaborativo. Si bien por momentos la profundidad técnica podría haber sido más ahondada, las ideas generales quedaron muy claras y los desafíos a lograr parecen ser lo suficientemente amplios como para captar el interés de cualquiera que tenga algo de gusto por el área, incluyéndome.

Recomendaría para futuras versiones del curso generar un documento más conciso y más actualizado que tratara los temas de esta lectura, puesto que si bien era una lectura entretenida, algunas discusiones ahí mencionadas parecen ya estar desactualizadas, mientras que otros temas que han surgido en los últimos años merecen ser incluidos sin duda. Finalmente, sería bueno saber si algunas de las preguntas abiertas que se plantean han sido parcial o totalmente resueltas, o el tipo de solución que parece estar encaminado a resolverlas.
